{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:05:02.499445300Z",
     "start_time": "2023-11-21T12:04:52.128856100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 13:04:54.877665: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-21 13:04:54.879735: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 13:04:54.916386: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 13:04:54.917281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 13:04:55.487187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from utils import SUPPORTED_MODELS\n",
    "from transformers import AutoConfig\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from pathlib import Path\n",
    "import openvino as ov\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "examine_fp16 = bool(1)  # otherwise bf16\n",
    "\n",
    "ov_config = {'PERFORMANCE_HINT': 'LATENCY', 'NUM_STREAMS': '1', \"CACHE_DIR\": \"\"}\n",
    "\n",
    "if examine_fp16:\n",
    "    model_id = \"red-pajama-3b-chat\"\n",
    "    models_dir = Path(\"./\")\n",
    "    model_dir = models_dir / model_id / \"FP16\"\n",
    "    # model_dir = models_dir / model_id / \"FP16_calibrated\"\n",
    "    # model_dir = models_dir / model_id / \"INT8_compressed_weights\"\n",
    "    model_configuration = SUPPORTED_MODELS[model_id]\n",
    "    # device = \"GPU\"\n",
    "    device = \"CPU\"\n",
    "else:\n",
    "    model_dir = Path(\"/home/devuser/nsavelye/workspace/openvino.genai/llm_bench/python/codegen-2B-multi/pytorch/dldt/FP32\")\n",
    "    model_configuration = {}\n",
    "    device = \"CPU\"\n",
    "    ov_config[\"INFERENCE_PRECISION_HINT\"] = \"f32\"     # otherwise BF16 is used\n",
    "\n",
    "core = ov.Core()\n",
    "tok = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "ov_model = OVModelForCausalLM.from_pretrained(model_dir, device=device, ov_config=ov_config,\n",
    "                                              config=AutoConfig.from_pretrained(model_dir, trust_remote_code=True),\n",
    "                                              trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                 | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception from src/inference/src/core.cpp:113:\n[ GENERAL_ERROR ] Check 'all_devices.size() > idx' failed at src/plugins/proxy/src/plugin.cpp:512:\nCannot get fallback device for index: 0. The total number of found devices is 0\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 17\u001B[0m\n\u001B[1;32m     12\u001B[0m     example_prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# this function implement Fourier transform for input array X\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     14\u001B[0m example_input \u001B[38;5;241m=\u001B[39m ov_model\u001B[38;5;241m.\u001B[39mmodel, main\u001B[38;5;241m.\u001B[39mget_inputs_for_calibration(\n\u001B[1;32m     15\u001B[0m     ov_model, tok, model_configuration, example_prompt)\n\u001B[0;32m---> 17\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mpartially_upcast_nodes_to_fp32\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartially_upcast_nodes_to_fp32\u001B[49m\u001B[43m(\u001B[49m\u001B[43mov_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m                                                                      \u001B[49m\u001B[43mhalf_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfp16\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexamine_fp16\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbf16\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# # model = model_upcast_utils.partially_upcast_nodes_to_fp32(ov_model.model, example_input)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# calibrated_model_dir = Path(f\"{model_dir}_calibrated\")\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# shutil.copytree(model_dir, calibrated_model_dir)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# ov_model.request = None\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# ov_model.compile()\u001B[39;00m\n",
      "File \u001B[0;32m~/nsavelye/workspace/fp16_calibration/fp16_calibration/partially_upcast_nodes_to_fp32.py:48\u001B[0m, in \u001B[0;36mpartially_upcast_nodes_to_fp32\u001B[0;34m(orig_model, example_input, half_type, batch_size, thresholds_per_op, verbose)\u001B[0m\n\u001B[1;32m     45\u001B[0m nodes_to_track_batch \u001B[38;5;241m=\u001B[39m [name_to_node_map[node_name] \u001B[38;5;28;01mfor\u001B[39;00m node_name \u001B[38;5;129;01min\u001B[39;00m nodes_to_track_names_batch]\n\u001B[1;32m     47\u001B[0m insert_results_for_tracked_ops(model, nodes_to_track_batch)\n\u001B[0;32m---> 48\u001B[0m fp16_full_net_infer_values_batch \u001B[38;5;241m=\u001B[39m \u001B[43minfer_full_net_in_fp16\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes_to_track_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhalf_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m fp16_infer_values_batch \u001B[38;5;241m=\u001B[39m infer_nodes(nodes_to_track_batch, fp16_full_net_infer_values_batch, device, half_type)\n\u001B[1;32m     51\u001B[0m fp32_infer_values_batch \u001B[38;5;241m=\u001B[39m infer_nodes(nodes_to_track_batch, fp16_full_net_infer_values_batch, device, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf32\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/nsavelye/workspace/fp16_calibration/fp16_calibration/partially_upcast_nodes_to_fp32.py:116\u001B[0m, in \u001B[0;36minfer_full_net_in_fp16\u001B[0;34m(nodes_to_track, orig_model, example_inputs, half_type)\u001B[0m\n\u001B[1;32m    114\u001B[0m core \u001B[38;5;241m=\u001B[39m ov\u001B[38;5;241m.\u001B[39mCore()\n\u001B[1;32m    115\u001B[0m config \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINFERENCE_PRECISION_HINT\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp16\u001B[39m\u001B[38;5;124m\"\u001B[39m} \u001B[38;5;28;01mif\u001B[39;00m half_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfp16\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m--> 116\u001B[0m exec_net \u001B[38;5;241m=\u001B[39m \u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43morig_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGPU\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mhalf_type\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfp16\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCPU\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m request \u001B[38;5;241m=\u001B[39m exec_net\u001B[38;5;241m.\u001B[39mcreate_infer_request()\n\u001B[1;32m    118\u001B[0m results \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39minfer(example_inputs)\n",
      "File \u001B[0;32m~/nsavelye/venvs/fp16_calibration/lib/python3.8/site-packages/openvino/runtime/ie_api.py:543\u001B[0m, in \u001B[0;36mCore.compile_model\u001B[0;34m(self, model, device_name, config)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m CompiledModel(\n\u001B[1;32m    539\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mcompile_model(model, {} \u001B[38;5;28;01mif\u001B[39;00m config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m config),\n\u001B[1;32m    540\u001B[0m     )\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m CompiledModel(\n\u001B[0;32m--> 543\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    544\u001B[0m )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Exception from src/inference/src/core.cpp:113:\n[ GENERAL_ERROR ] Check 'all_devices.size() > idx' failed at src/plugins/proxy/src/plugin.cpp:512:\nCannot get fallback device for index: 0. The total number of found devices is 0\n\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import shutil\n",
    "import partially_upcast_nodes_to_fp32\n",
    "import model_upcast_utils\n",
    "import main\n",
    "importlib.reload(partially_upcast_nodes_to_fp32)\n",
    "importlib.reload(main)\n",
    "\n",
    "if examine_fp16:\n",
    "    example_prompt = \"<human>: Which lakes are near Munich?\\n<bot>:\"\n",
    "else:\n",
    "    example_prompt = \"# this function implement Fourier transform for input array X\"\n",
    "\n",
    "example_input = ov_model.model, main.get_inputs_for_calibration(\n",
    "    ov_model, tok, model_configuration, example_prompt)\n",
    "\n",
    "model = partially_upcast_nodes_to_fp32.partially_upcast_nodes_to_fp32(ov_model.model, example_input, batch_size=50, verbose=True,\n",
    "                                                                      half_type=\"fp16\" if examine_fp16 else \"bf16\")\n",
    "# # model = model_upcast_utils.partially_upcast_nodes_to_fp32(ov_model.model, example_input)\n",
    "# calibrated_model_dir = Path(f\"{model_dir}_calibrated\")\n",
    "# shutil.copytree(model_dir, calibrated_model_dir)\n",
    "# ov.save_model(model, calibrated_model_dir / \"openvino_model.xml\")\n",
    "#\n",
    "# ov_model.model = model\n",
    "# ov_model._original_model = model\n",
    "# ov_model.request = None\n",
    "# ov_model.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:08:17.663391300Z",
     "start_time": "2023-11-21T12:08:17.452952700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/devuser/nsavelye/venvs/fp16_calibration/lib/python3.8/site-packages/optimum/intel/openvino/modeling_decoder.py:388: FutureWarning: `shared_memory` is deprecated and will be removed in 2024.0. Value of `shared_memory` is going to override `share_inputs` value. Please use only `share_inputs` explicitly.\n",
      "  self.request.start_async(inputs, shared_memory=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this function implement Fourier transform for imput array X\n",
      "    # and output array Y\n",
      "    def fft(self, X):\n",
      "        N = len(X)\n",
      "        Y = np.zeros(N)\n",
      "        for i in range(N):\n",
      "            Y[i] = np.real(np.fft.fft(X[i]))\n",
      "        return Y\n",
      "\n",
      "    # this function implement inverse Fourier transform for output array Y\n",
      "    # and input array X\n",
      "    def ifft("
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import main\n",
    "importlib.reload(main)\n",
    "\n",
    "if examine_fp16:\n",
    "    prompt = \"Which lakes are near Munich?\"\n",
    "    generation_kwargs = dict(\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.1,\n",
    "        do_sample=0.1 > 0.0,\n",
    "        top_p=1.0,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "else:\n",
    "    prompt = \"# this function implement Fourier transform for input array X\"\n",
    "    generation_kwargs = dict(\n",
    "        max_new_tokens=100,\n",
    "        num_beams=1,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# print(run_generate(ov_model, prompt, model_configuration, **generation_kwargs))\n",
    "for text in main.run_generate(ov_model, tok, prompt, model_configuration, pass_attention_mask=not examine_fp16, **generation_kwargs):\n",
    "    print(text, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:43:03.629702400Z",
     "start_time": "2023-11-21T10:42:34.538105100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-20T14:44:48.866704800Z",
     "start_time": "2023-11-20T14:44:48.863688200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
