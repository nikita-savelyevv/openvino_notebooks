{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:20:55.402084Z",
     "start_time": "2023-11-21T12:20:45.080783600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 13:20:47.866005: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-21 13:20:47.867812: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 13:20:47.902410: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-21 13:20:47.903724: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 13:20:48.486091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from utils import SUPPORTED_MODELS\n",
    "from transformers import AutoConfig\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from pathlib import Path\n",
    "import openvino as ov\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "examine_fp16 = bool(0)  # otherwise bf16\n",
    "\n",
    "ov_config = {'PERFORMANCE_HINT': 'LATENCY', 'NUM_STREAMS': '1', \"CACHE_DIR\": \"\"}\n",
    "\n",
    "if examine_fp16:\n",
    "    model_id = \"red-pajama-3b-chat\"\n",
    "    models_dir = Path(\"./\")\n",
    "    model_dir = models_dir / model_id / \"FP16\"\n",
    "    # model_dir = models_dir / model_id / \"FP16_calibrated\"\n",
    "    # model_dir = models_dir / model_id / \"INT8_compressed_weights\"\n",
    "    model_configuration = SUPPORTED_MODELS[model_id]\n",
    "    device = \"GPU\"\n",
    "    # device = \"CPU\"\n",
    "else:\n",
    "    model_dir = Path(\"/home/devuser/nsavelye/workspace/openvino.genai/llm_bench/python/codegen-2B-multi/pytorch/dldt/FP32\")\n",
    "    model_configuration = {}\n",
    "    device = \"CPU\"\n",
    "    # ov_config[\"INFERENCE_PRECISION_HINT\"] = \"f32\"     # otherwise BF16 is used\n",
    "\n",
    "core = ov.Core()\n",
    "tok = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "ov_model = OVModelForCausalLM.from_pretrained(model_dir, device=device, ov_config=ov_config,\n",
    "                                              config=AutoConfig.from_pretrained(model_dir, trust_remote_code=True),\n",
    "                                              trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[    2,   428,  2163,  3494, 34296,  5277,  6121,   329,  5128,\n",
      "         7177,  1395]]), 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'past_key_values.0.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.0.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.1.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.1.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.2.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.2.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.3.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.3.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.4.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.4.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.5.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.5.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.6.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.6.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.7.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.7.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.8.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.8.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.9.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.9.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.10.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.10.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.11.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.11.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.12.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.12.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.13.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.13.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.14.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.14.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.15.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.15.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.16.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.16.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.17.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.17.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.18.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.18.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.19.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.19.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.20.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.20.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.21.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.21.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.22.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.22.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.23.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.23.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.24.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.24.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.25.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.25.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.26.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.26.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.27.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.27.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.28.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.28.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.29.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.29.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.30.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.30.value': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.31.key': <Tensor: shape[1,32,0,80] type: bf16>, 'past_key_values.31.value': <Tensor: shape[1,32,0,80] type: bf16>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                 | 0/4 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception from src/inference/src/infer_request.cpp:231:\nException from src/plugins/intel_cpu/src/node.cpp:1662:\nShape inference of Multiply node with name __module.model.transformer.h.0.attn/aten::mul/Multiply_526 failed: Exception from src/plugins/intel_cpu/src/shape_inference/custom/eltwise.cpp:47:\nEltwise shape infer input shapes dim index: 1 mismatch\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m example_input \u001B[38;5;241m=\u001B[39m main\u001B[38;5;241m.\u001B[39mget_inputs_for_calibration(ov_model, tok, model_configuration, example_prompt)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(example_input)\n\u001B[0;32m---> 17\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mpartially_upcast_nodes_to_fp32\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartially_upcast_nodes_to_fp32\u001B[49m\u001B[43m(\u001B[49m\u001B[43mov_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m                                                                      \u001B[49m\u001B[43mhalf_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf16\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexamine_fp16\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbf16\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# model = model_upcast_utils.partially_upcast_nodes_to_fp32(ov_model.model, example_input)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m calibrated_model_dir \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_calibrated\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/nsavelye/workspace/fp16_calibration/fp16_calibration/partially_upcast_nodes_to_fp32.py:48\u001B[0m, in \u001B[0;36mpartially_upcast_nodes_to_fp32\u001B[0;34m(orig_model, example_input, half_type, batch_size, thresholds_per_op, verbose)\u001B[0m\n\u001B[1;32m     45\u001B[0m nodes_to_track_batch \u001B[38;5;241m=\u001B[39m [name_to_node_map[node_name] \u001B[38;5;28;01mfor\u001B[39;00m node_name \u001B[38;5;129;01min\u001B[39;00m nodes_to_track_names_batch]\n\u001B[1;32m     47\u001B[0m insert_results_for_tracked_ops(model, nodes_to_track_batch)\n\u001B[0;32m---> 48\u001B[0m fp16_full_net_infer_values_batch \u001B[38;5;241m=\u001B[39m \u001B[43minfer_full_net_in_fp16\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes_to_track_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhalf_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m fp16_infer_values_batch \u001B[38;5;241m=\u001B[39m infer_nodes(nodes_to_track_batch, fp16_full_net_infer_values_batch, device, half_type)\n\u001B[1;32m     51\u001B[0m fp32_infer_values_batch \u001B[38;5;241m=\u001B[39m infer_nodes(nodes_to_track_batch, fp16_full_net_infer_values_batch, device, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf32\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/nsavelye/workspace/fp16_calibration/fp16_calibration/partially_upcast_nodes_to_fp32.py:118\u001B[0m, in \u001B[0;36minfer_full_net_in_fp16\u001B[0;34m(nodes_to_track, orig_model, example_inputs, half_type)\u001B[0m\n\u001B[1;32m    115\u001B[0m exec_net \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mcompile_model(orig_model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPU\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m half_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf16\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCPU\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    116\u001B[0m                               config\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINFERENCE_PRECISION_HINT\u001B[39m\u001B[38;5;124m\"\u001B[39m: half_type})\n\u001B[1;32m    117\u001B[0m request \u001B[38;5;241m=\u001B[39m exec_net\u001B[38;5;241m.\u001B[39mcreate_infer_request()\n\u001B[0;32m--> 118\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m results_map \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, val \u001B[38;5;129;01min\u001B[39;00m results\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/nsavelye/venvs/fp16_calibration/lib/python3.8/site-packages/openvino/runtime/ie_api.py:143\u001B[0m, in \u001B[0;36mInferRequest.infer\u001B[0;34m(self, inputs, share_inputs, share_outputs, shared_memory)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minfer\u001B[39m(\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     70\u001B[0m     inputs: Any \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     74\u001B[0m     shared_memory: Any \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     75\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OVDict:\n\u001B[1;32m     76\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Infers specified input(s) in synchronous mode.\u001B[39;00m\n\u001B[1;32m     77\u001B[0m \n\u001B[1;32m     78\u001B[0m \u001B[38;5;124;03m    Blocks all methods of InferRequest while request is running.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;124;03m    :rtype: OVDict\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OVDict(\u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_data_dispatch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_shared\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_deprecated_memory_arg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshared_memory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshare_inputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshare_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshare_outputs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Exception from src/inference/src/infer_request.cpp:231:\nException from src/plugins/intel_cpu/src/node.cpp:1662:\nShape inference of Multiply node with name __module.model.transformer.h.0.attn/aten::mul/Multiply_526 failed: Exception from src/plugins/intel_cpu/src/shape_inference/custom/eltwise.cpp:47:\nEltwise shape infer input shapes dim index: 1 mismatch\n\n\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import shutil\n",
    "import partially_upcast_nodes_to_fp32\n",
    "import model_upcast_utils\n",
    "import main\n",
    "importlib.reload(partially_upcast_nodes_to_fp32)\n",
    "importlib.reload(main)\n",
    "\n",
    "if examine_fp16:\n",
    "    example_prompt = \"<human>: Which lakes are near Munich?\\n<bot>:\"\n",
    "else:\n",
    "    example_prompt = \"# this function implement Fourier transform for imput array X\"\n",
    "\n",
    "example_input = main.get_inputs_for_calibration(ov_model, tok, model_configuration, example_prompt)\n",
    "if not examine_fp16:\n",
    "    position_ids = np.cumsum(example_input[\"attention_mask\"], axis=1) - 1\n",
    "    position_ids[example_input[\"attention_mask\"] == 0] = 1\n",
    "    example_input[\"position_ids\"] = position_ids\n",
    "\n",
    "# shape_str = \"\"\n",
    "# for k, v in example_input.items():\n",
    "#     # np.save(f\"example_input/{k}.npy\", v.data)\n",
    "#     shape_str += f\"{k}{list(v.shape)},\".replace(' ', '')\n",
    "# print(shape_str)\n",
    "\n",
    "model = partially_upcast_nodes_to_fp32.partially_upcast_nodes_to_fp32(ov_model.model, example_input, batch_size=50, verbose=True,\n",
    "                                                                      half_type=\"f16\" if examine_fp16 else \"bf16\")\n",
    "# model = model_upcast_utils.partially_upcast_nodes_to_fp32(ov_model.model, example_input)\n",
    "calibrated_model_dir = Path(f\"{model_dir}_calibrated\")\n",
    "shutil.copytree(model_dir, calibrated_model_dir)\n",
    "ov.save_model(model, calibrated_model_dir / \"openvino_model.xml\")\n",
    "ov_model.model = model\n",
    "ov_model._original_model = model\n",
    "ov_model.request = None\n",
    "ov_model.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T13:58:48.714063700Z",
     "start_time": "2023-11-21T13:58:18.686524200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# this function implement Fourier transform for input array X\n",
      "    # and output array Y\n",
      "    #\n",
      "    # X: input array\n",
      "    # Y: output array\n",
      "    #\n",
      "    # return:\n",
      "    #   0:\n",
      "\n",
      "  \n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    #\n",
      "    "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import main\n",
    "importlib.reload(main)\n",
    "\n",
    "if examine_fp16:\n",
    "    prompt = \"Which lakes are near Munich?\"\n",
    "    generation_kwargs = dict(\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.1,\n",
    "        do_sample=0.1 > 0.0,\n",
    "        top_p=1.0,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "else:\n",
    "    prompt = \"# this function implements Fourier transform for input array X\"\n",
    "    generation_kwargs = dict(\n",
    "        max_new_tokens=100,\n",
    "        num_beams=1,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "\n",
    "# print(run_generate(ov_model, prompt, model_configuration, **generation_kwargs))\n",
    "for text in main.run_generate(ov_model, tok, prompt, model_configuration, **generation_kwargs):\n",
    "    print(text, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:22:49.006294900Z",
     "start_time": "2023-11-21T12:22:39.582693600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
