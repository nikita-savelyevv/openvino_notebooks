{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:05:07.070964600Z",
     "start_time": "2023-12-01T14:05:03.149591200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 23:12:47.109746: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 23:12:47.120678: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 23:12:47.145686: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 23:12:47.146142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 23:12:47.631061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from pathlib import Path\n",
    "import openvino as ov\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "\n",
    "ov_config = {'PERFORMANCE_HINT': 'LATENCY', 'NUM_STREAMS': '1', \"CACHE_DIR\": \"\"}\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "models_dir = Path(\"./models\")\n",
    "\n",
    "# MODEL_ID = \"red-pajama-3b-chat\"\n",
    "MODEL_ID = \"T5\"\n",
    "# MODEL_ID = \"tiny-sd-unet\"\n",
    "# MODEL_ID = \"codegen-2B-multi\"\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"tiny-sd-unet\", \"T5\"]:\n",
    "    half_type = \"f16\"\n",
    "    model_dir = models_dir / MODEL_ID / \"FP16\"\n",
    "    # model_dir = models_dir / MODEL_ID / \"FP16_calibrated\"\n",
    "    # model_dir = models_dir / MODEL_ID / \"INT8_compressed_weights\"\n",
    "    device = \"GPU\"\n",
    "    # device = \"CPU\"\n",
    "\n",
    "    if MODEL_ID == \"red-pajama-3b-chat\":\n",
    "        example_prompt = \"<human>: Which lakes are near Munich?\\\\n<bot>:\"\n",
    "    elif MODEL_ID == \"T5\":\n",
    "        example_prompt = \"ultra close color photo portrait of rainbow owl with deer horns in the woods\"\n",
    "    elif MODEL_ID == \"tiny-sd-unet\":\n",
    "        with open(\"unet_example_input.pkl\", \"rb\") as f:\n",
    "            unet_example_input = pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "elif MODEL_ID == \"codegen-2B-multi\":\n",
    "    half_type = \"bf16\"\n",
    "    model_dir = Path(\"/home/devuser/nsavelye/workspace/openvino.genai/llm_bench/python/codegen-2B-multi/pytorch/dldt/FP32\")\n",
    "    device = \"CPU\"\n",
    "    # ov_config[\"INFERENCE_PRECISION_HINT\"] = \"f32\"     # otherwise BF16 is used\n",
    "    example_prompt = \"# this function implement Fourier transform for imput array X\"\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\"]:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    ov_model_for_causal_lm = OVModelForCausalLM.from_pretrained(\n",
    "        model_dir, device=device, ov_config=ov_config,\n",
    "        config=AutoConfig.from_pretrained(model_dir, trust_remote_code=True), trust_remote_code=True)\n",
    "    model = ov_model_for_causal_lm.model\n",
    "elif MODEL_ID == \"T5\":\n",
    "    model = core.read_model(model_dir / \"encoder_ir.xml\")\n",
    "elif MODEL_ID == \"tiny-sd-unet\":\n",
    "    model = core.read_model(model_dir / \"unet.xml\")\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import shutil\n",
    "import partially_upcast_nodes_to_fp32\n",
    "import model_upcast_utils\n",
    "import main\n",
    "importlib.reload(partially_upcast_nodes_to_fp32)\n",
    "importlib.reload(main)\n",
    "\n",
    "SAVE_MODEL = bool(1)\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\"]:\n",
    "    batch_size = 50\n",
    "    example_input = main.get_inputs_for_calibration(ov_model_for_causal_lm, tok, example_prompt)\n",
    "    if MODEL_ID == \"codegen-2B-multi\":\n",
    "        position_ids = np.cumsum(example_input[\"attention_mask\"], axis=1) - 1\n",
    "        position_ids[example_input[\"attention_mask\"] == 0] = 1\n",
    "        example_input[\"position_ids\"] = position_ids\n",
    "elif MODEL_ID == \"T5\":\n",
    "    batch_size = 50\n",
    "    # from diffusers import DiffusionPipeline\n",
    "    # tokenizer = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-M-v1.0\").tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models_dir / MODEL_ID / \"tokenizer\")\n",
    "    example_input = tokenizer(example_prompt, max_length=77, padding=\"max_length\", return_tensors=\"np\").input_ids\n",
    "elif MODEL_ID == \"tiny-sd-unet\":\n",
    "    batch_size = -1\n",
    "    example_input = unet_example_input\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "# shape_str = \"\"\n",
    "# for k, v in example_input.items():\n",
    "#     # np.save(f\"example_input/{k}.npy\", v.data)\n",
    "#     shape_str += f\"{k}{list(v.shape)},\".replace(' ', '')\n",
    "# print(shape_str)\n",
    "\n",
    "# upcasted_model = model_upcast_utils.partially_upcast_nodes_to_fp32(model, example_input)\n",
    "upcast_ratio = 0.1\n",
    "upcasted_model = partially_upcast_nodes_to_fp32.partially_upcast_nodes_to_fp32(\n",
    "    model, example_input, batch_size=batch_size, verbose=True, half_type=half_type, upcast_ratio=upcast_ratio)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    calibrated_model_dir = Path(f\"{model_dir}_calibrated_{upcast_ratio:.2f}\")\n",
    "    if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\"]:\n",
    "        shutil.copytree(model_dir, calibrated_model_dir)\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"openvino_model.xml\")\n",
    "    elif MODEL_ID == \"T5\":\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"encoder_ir_calibrated.xml\", compress_to_fp16=True)\n",
    "    elif MODEL_ID == \"tiny-sd-unet\":\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"unet_calibrated.xml\")\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\"]:\n",
    "    ov_model_for_causal_lm.model = upcasted_model\n",
    "    ov_model_for_causal_lm.request = None\n",
    "    ov_model_for_causal_lm.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T14:06:25.002717100Z",
     "start_time": "2023-12-01T14:06:24.873668700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "safety_checker/model.safetensors not found\n",
      "\n",
      "A mixture of fp16 and non-fp16 filenames will be loaded.\n",
      "Loaded fp16 filenames:\n",
      "[text_encoder/pytorch_model.fp16-00001-of-00002.bin, text_encoder/pytorch_model.fp16-00002-of-00002.bin, unet/diffusion_pytorch_model.fp16.bin]\n",
      "Loaded non-fp16 filenames:\n",
      "[safety_checker/pytorch_model.bin, watermarker/diffusion_pytorch_model.bin\n",
      "If this behavior is not expected, please check your folder structure.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa0fb3770d2b4d878aefe2269d88b3e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c0ec8a41cdf4d48b7e834b2a71bef88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "376a5092071040799f72f928b5a40c50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import main\n",
    "importlib.reload(main)\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\"]:\n",
    "    if MODEL_ID == \"red-pajama-3b-chat\":\n",
    "        prompt = \"Which lakes are near Munich?\"\n",
    "    else:\n",
    "        promt = example_prompt\n",
    "    if MODEL_ID == \"red-pajama-3b-chat\":\n",
    "        generation_kwargs = dict(\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.1,\n",
    "            do_sample=0.1 > 0.0,\n",
    "            top_p=1.0,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.2\n",
    "        )\n",
    "    else:\n",
    "        generation_kwargs = dict(\n",
    "            max_new_tokens=100,\n",
    "            num_beams=1,\n",
    "            use_cache=True,\n",
    "        )\n",
    "\n",
    "    # print(run_generate(ov_model, prompt, model_configuration, **generation_kwargs))\n",
    "    for text in main.run_generate(ov_model_for_causal_lm, tok, prompt, **generation_kwargs):\n",
    "        print(text, end=\"\")\n",
    "elif MODEL_ID == \"T5\":\n",
    "    from IPython.display import display\n",
    "    from deepfloyd_utils import TextEncoder, UnetFirstStage, pt_to_pil\n",
    "    from diffusers import DiffusionPipeline\n",
    "    import torch\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../notebooks/utils\")\n",
    "\n",
    "    prompt = 'ultra close color photo portrait of rainbow owl with deer horns in the woods'\n",
    "    negative_prompt = 'blurred unreal uncentered occluded'\n",
    "\n",
    "    RANDOM_SEED = 42\n",
    "    N_DIFFUSION_STEPS = 50\n",
    "    checkpoint_variant = 'fp16'\n",
    "    model_dtype = torch.float32\n",
    "\n",
    "    stage_1 = DiffusionPipeline.from_pretrained(\n",
    "        \"DeepFloyd/IF-I-M-v1.0\",\n",
    "        variant=checkpoint_variant,\n",
    "        torch_dtype=model_dtype\n",
    "    )\n",
    "\n",
    "    # Initialize TextEncoder wrapper class\n",
    "    stage_1.text_encoder = TextEncoder(calibrated_model_dir / \"encoder_ir_calibrated.xml\", dtype=model_dtype, device=device)\n",
    "\n",
    "    # Generate text embeddings\n",
    "    prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt, negative_prompt=negative_prompt)\n",
    "\n",
    "    # Initialize the First Stage UNet wrapper class\n",
    "    stage_1.unet = UnetFirstStage(\n",
    "        \"/home/guest/nsavelye/workspace/fp16_calibration/notebooks/238-deepfloyd-if/models_new/unet_ir_I.xml\",\n",
    "        stage_1.unet.config,\n",
    "        dtype=model_dtype,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Fix PRNG seed\n",
    "    generator = torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    # Inference\n",
    "    image = stage_1(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds,\n",
    "                    generator=generator, output_type=\"pt\", num_inference_steps=N_DIFFUSION_STEPS).images\n",
    "\n",
    "    # Show the image\n",
    "    display(pt_to_pil(image)[0])\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-01T13:15:28.070743600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
