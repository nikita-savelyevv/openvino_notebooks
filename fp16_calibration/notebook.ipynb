{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-13T09:30:23.480102500Z",
     "start_time": "2023-12-13T09:30:06.845718900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 10:30:10.223361: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 10:30:10.225225: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 10:30:10.265773: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 10:30:10.266960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 10:30:11.178291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from pathlib import Path\n",
    "import openvino as ov\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "\n",
    "ov_config = {'PERFORMANCE_HINT': 'LATENCY', 'NUM_STREAMS': '1', \"CACHE_DIR\": \"\"}\n",
    "\n",
    "core = ov.Core()\n",
    "\n",
    "models_dir = Path(\"./models\")\n",
    "\n",
    "# MODEL_ID = \"red-pajama-3b-chat\"\n",
    "# MODEL_ID = \"T5\"\n",
    "# MODEL_ID = \"tiny-sd-unet\"\n",
    "# MODEL_ID = \"codegen-2B-multi\"\n",
    "MODEL_ID = \"gpt-neox-20b\"\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"tiny-sd-unet\", \"T5\"]:\n",
    "    half_type = \"f16\"\n",
    "    model_dir = models_dir / MODEL_ID / \"FP16\"\n",
    "    # model_dir = models_dir / MODEL_ID / \"FP16_calibrated\"\n",
    "    # model_dir = models_dir / MODEL_ID / \"INT8_compressed_weights\"\n",
    "    device = \"GPU\"\n",
    "    # device = \"CPU\"\n",
    "\n",
    "    if MODEL_ID == \"red-pajama-3b-chat\":\n",
    "        example_prompt = \"<human>: Which lakes are near Munich?\\\\n<bot>:\"\n",
    "    elif MODEL_ID == \"T5\":\n",
    "        example_prompt = \"ultra close color photo portrait of rainbow owl with deer horns in the woods\"\n",
    "    elif MODEL_ID == \"tiny-sd-unet\":\n",
    "        with open(\"unet_example_input.pkl\", \"rb\") as f:\n",
    "            unet_example_input = pickle.load(f)\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "elif MODEL_ID in [\"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "    half_type = \"bf16\"\n",
    "    device = \"CPU\"\n",
    "    # ov_config[\"INFERENCE_PRECISION_HINT\"] = \"f32\"     # otherwise BF16 is used\n",
    "    if MODEL_ID == \"codegen-2B-multi\":\n",
    "        model_dir = Path(\"/home/devuser/nsavelye/workspace/openvino.genai/llm_bench/python/codegen-2B-multi/pytorch/dldt/FP32\")\n",
    "        example_prompt = \"# this function implement Fourier transform for imput array X\"\n",
    "    elif MODEL_ID == \"gpt-neox-20b\":\n",
    "        model_dir = Path(\"/home/devuser/nsavelye/workspace/openvino.genai/llm_bench/python/gpt-neox-20b/fp16/pytorch/dldt/FP16\")\n",
    "        example_prompt = \"Which lakes are near Munich?\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "    tok = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "    ov_model_for_causal_lm = OVModelForCausalLM.from_pretrained(\n",
    "        model_dir, device=device, ov_config=ov_config,\n",
    "        config=AutoConfig.from_pretrained(model_dir, trust_remote_code=True), trust_remote_code=True)\n",
    "    model = ov_model_for_causal_lm.model\n",
    "elif MODEL_ID == \"T5\":\n",
    "    model = core.read_model(model_dir / \"encoder_ir.xml\")\n",
    "elif MODEL_ID == \"tiny-sd-unet\":\n",
    "    model = core.read_model(model_dir / \"unet.xml\")\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [06:38<00:00, 398.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQNR 1.00-quantile equals 82.52. Upcasted 264 of 264 considered nodes:\n",
      "__module.model.gpt_neox.layers.0.mlp.dense_h_to_4h/aten::linear/MatMul_309\n",
      "__module.model.gpt_neox.layers.0.mlp.dense_4h_to_h/aten::linear/MatMul_318\n",
      "__module.model.gpt_neox.layers.0.attention.query_key_value/aten::linear/MatMul_100\n",
      "__module.model.gpt_neox.layers.0.attention/aten::baddbmm/Multiply_289\n",
      "__module.model.gpt_neox.layers.0.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.0.attention.dense/aten::linear/MatMul_308\n",
      "__module.model.gpt_neox.layers.1.mlp.dense_h_to_4h/aten::linear/MatMul_531\n",
      "__module.model.gpt_neox.layers.1.mlp.dense_4h_to_h/aten::linear/MatMul_540\n",
      "__module.model.gpt_neox.layers.1.attention.query_key_value/aten::linear/MatMul_322\n",
      "__module.model.gpt_neox.layers.1.attention/aten::baddbmm/Multiply_511\n",
      "__module.model.gpt_neox.layers.1.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.1.attention.dense/aten::linear/MatMul_530\n",
      "__module.model.gpt_neox.layers.2.mlp.dense_h_to_4h/aten::linear/MatMul_753\n",
      "__module.model.gpt_neox.layers.2.mlp.dense_4h_to_h/aten::linear/MatMul_762\n",
      "__module.model.gpt_neox.layers.2.attention.query_key_value/aten::linear/MatMul_544\n",
      "__module.model.gpt_neox.layers.2.attention/aten::baddbmm/Multiply_733\n",
      "__module.model.gpt_neox.layers.2.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.2.attention.dense/aten::linear/MatMul_752\n",
      "__module.model.gpt_neox.layers.3.mlp.dense_h_to_4h/aten::linear/MatMul_975\n",
      "__module.model.gpt_neox.layers.3.mlp.dense_4h_to_h/aten::linear/MatMul_984\n",
      "__module.model.gpt_neox.layers.3.attention.query_key_value/aten::linear/MatMul_766\n",
      "__module.model.gpt_neox.layers.3.attention/aten::baddbmm/Multiply_955\n",
      "__module.model.gpt_neox.layers.3.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.3.attention.dense/aten::linear/MatMul_974\n",
      "__module.model.gpt_neox.layers.4.mlp.dense_h_to_4h/aten::linear/MatMul_1197\n",
      "__module.model.gpt_neox.layers.4.mlp.dense_4h_to_h/aten::linear/MatMul_1206\n",
      "__module.model.gpt_neox.layers.4.attention.query_key_value/aten::linear/MatMul_988\n",
      "__module.model.gpt_neox.layers.4.attention/aten::baddbmm/Multiply_1177\n",
      "__module.model.gpt_neox.layers.4.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.4.attention.dense/aten::linear/MatMul_1196\n",
      "__module.model.gpt_neox.layers.5.mlp.dense_h_to_4h/aten::linear/MatMul_1419\n",
      "__module.model.gpt_neox.layers.5.mlp.dense_4h_to_h/aten::linear/MatMul_1428\n",
      "__module.model.gpt_neox.layers.5.attention.query_key_value/aten::linear/MatMul_1210\n",
      "__module.model.gpt_neox.layers.5.attention/aten::baddbmm/Multiply_1399\n",
      "__module.model.gpt_neox.layers.5.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.5.attention.dense/aten::linear/MatMul_1418\n",
      "__module.model.gpt_neox.layers.6.mlp.dense_h_to_4h/aten::linear/MatMul_1641\n",
      "__module.model.gpt_neox.layers.6.mlp.dense_4h_to_h/aten::linear/MatMul_1650\n",
      "__module.model.gpt_neox.layers.6.attention.query_key_value/aten::linear/MatMul_1432\n",
      "__module.model.gpt_neox.layers.6.attention/aten::baddbmm/Multiply_1621\n",
      "__module.model.gpt_neox.layers.6.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.6.attention.dense/aten::linear/MatMul_1640\n",
      "__module.model.gpt_neox.layers.7.mlp.dense_h_to_4h/aten::linear/MatMul_1863\n",
      "__module.model.gpt_neox.layers.7.mlp.dense_4h_to_h/aten::linear/MatMul_1872\n",
      "__module.model.gpt_neox.layers.7.attention.query_key_value/aten::linear/MatMul_1654\n",
      "__module.model.gpt_neox.layers.7.attention/aten::baddbmm/Multiply_1843\n",
      "__module.model.gpt_neox.layers.7.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.7.attention.dense/aten::linear/MatMul_1862\n",
      "__module.model.gpt_neox.layers.8.mlp.dense_h_to_4h/aten::linear/MatMul_2085\n",
      "__module.model.gpt_neox.layers.8.mlp.dense_4h_to_h/aten::linear/MatMul_2094\n",
      "__module.model.gpt_neox.layers.8.attention.query_key_value/aten::linear/MatMul_1876\n",
      "__module.model.gpt_neox.layers.8.attention/aten::baddbmm/Multiply_2065\n",
      "__module.model.gpt_neox.layers.8.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.8.attention.dense/aten::linear/MatMul_2084\n",
      "__module.model.gpt_neox.layers.9.mlp.dense_h_to_4h/aten::linear/MatMul_2307\n",
      "__module.model.gpt_neox.layers.9.mlp.dense_4h_to_h/aten::linear/MatMul_2316\n",
      "__module.model.gpt_neox.layers.9.attention.query_key_value/aten::linear/MatMul_2098\n",
      "__module.model.gpt_neox.layers.9.attention/aten::baddbmm/Multiply_2287\n",
      "__module.model.gpt_neox.layers.9.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.9.attention.dense/aten::linear/MatMul_2306\n",
      "__module.model.gpt_neox.layers.10.mlp.dense_h_to_4h/aten::linear/MatMul_2529\n",
      "__module.model.gpt_neox.layers.10.mlp.dense_4h_to_h/aten::linear/MatMul_2538\n",
      "__module.model.gpt_neox.layers.10.attention.query_key_value/aten::linear/MatMul_2320\n",
      "__module.model.gpt_neox.layers.10.attention/aten::baddbmm/Multiply_2509\n",
      "__module.model.gpt_neox.layers.10.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.10.attention.dense/aten::linear/MatMul_2528\n",
      "__module.model.gpt_neox.layers.11.mlp.dense_h_to_4h/aten::linear/MatMul_2751\n",
      "__module.model.gpt_neox.layers.11.mlp.dense_4h_to_h/aten::linear/MatMul_2760\n",
      "__module.model.gpt_neox.layers.11.attention.query_key_value/aten::linear/MatMul_2542\n",
      "__module.model.gpt_neox.layers.11.attention/aten::baddbmm/Multiply_2731\n",
      "__module.model.gpt_neox.layers.11.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.11.attention.dense/aten::linear/MatMul_2750\n",
      "__module.model.gpt_neox.layers.12.mlp.dense_h_to_4h/aten::linear/MatMul_2973\n",
      "__module.model.gpt_neox.layers.12.mlp.dense_4h_to_h/aten::linear/MatMul_2982\n",
      "__module.model.gpt_neox.layers.12.attention.query_key_value/aten::linear/MatMul_2764\n",
      "__module.model.gpt_neox.layers.12.attention/aten::baddbmm/Multiply_2953\n",
      "__module.model.gpt_neox.layers.12.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.12.attention.dense/aten::linear/MatMul_2972\n",
      "__module.model.gpt_neox.layers.13.mlp.dense_h_to_4h/aten::linear/MatMul_3195\n",
      "__module.model.gpt_neox.layers.13.mlp.dense_4h_to_h/aten::linear/MatMul_3204\n",
      "__module.model.gpt_neox.layers.13.attention.query_key_value/aten::linear/MatMul_2986\n",
      "__module.model.gpt_neox.layers.13.attention/aten::baddbmm/Multiply_3175\n",
      "__module.model.gpt_neox.layers.13.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.13.attention.dense/aten::linear/MatMul_3194\n",
      "__module.model.gpt_neox.layers.14.mlp.dense_h_to_4h/aten::linear/MatMul_3417\n",
      "__module.model.gpt_neox.layers.14.mlp.dense_4h_to_h/aten::linear/MatMul_3426\n",
      "__module.model.gpt_neox.layers.14.attention.query_key_value/aten::linear/MatMul_3208\n",
      "__module.model.gpt_neox.layers.14.attention/aten::baddbmm/Multiply_3397\n",
      "__module.model.gpt_neox.layers.14.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.14.attention.dense/aten::linear/MatMul_3416\n",
      "__module.model.gpt_neox.layers.15.mlp.dense_h_to_4h/aten::linear/MatMul_3639\n",
      "__module.model.gpt_neox.layers.15.mlp.dense_4h_to_h/aten::linear/MatMul_3648\n",
      "__module.model.gpt_neox.layers.15.attention.query_key_value/aten::linear/MatMul_3430\n",
      "__module.model.gpt_neox.layers.15.attention/aten::baddbmm/Multiply_3619\n",
      "__module.model.gpt_neox.layers.15.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.15.attention.dense/aten::linear/MatMul_3638\n",
      "__module.model.gpt_neox.layers.16.mlp.dense_h_to_4h/aten::linear/MatMul_3861\n",
      "__module.model.gpt_neox.layers.16.mlp.dense_4h_to_h/aten::linear/MatMul_3870\n",
      "__module.model.gpt_neox.layers.16.attention.query_key_value/aten::linear/MatMul_3652\n",
      "__module.model.gpt_neox.layers.16.attention/aten::baddbmm/Multiply_3841\n",
      "__module.model.gpt_neox.layers.16.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.16.attention.dense/aten::linear/MatMul_3860\n",
      "__module.model.gpt_neox.layers.17.mlp.dense_h_to_4h/aten::linear/MatMul_4083\n",
      "__module.model.gpt_neox.layers.17.mlp.dense_4h_to_h/aten::linear/MatMul_4092\n",
      "__module.model.gpt_neox.layers.17.attention.query_key_value/aten::linear/MatMul_3874\n",
      "__module.model.gpt_neox.layers.17.attention/aten::baddbmm/Multiply_4063\n",
      "__module.model.gpt_neox.layers.17.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.17.attention.dense/aten::linear/MatMul_4082\n",
      "__module.model.gpt_neox.layers.18.mlp.dense_h_to_4h/aten::linear/MatMul_4305\n",
      "__module.model.gpt_neox.layers.18.mlp.dense_4h_to_h/aten::linear/MatMul_4314\n",
      "__module.model.gpt_neox.layers.18.attention.query_key_value/aten::linear/MatMul_4096\n",
      "__module.model.gpt_neox.layers.18.attention/aten::baddbmm/Multiply_4285\n",
      "__module.model.gpt_neox.layers.18.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.18.attention.dense/aten::linear/MatMul_4304\n",
      "__module.model.gpt_neox.layers.19.mlp.dense_h_to_4h/aten::linear/MatMul_4527\n",
      "__module.model.gpt_neox.layers.19.mlp.dense_4h_to_h/aten::linear/MatMul_4536\n",
      "__module.model.gpt_neox.layers.19.attention.query_key_value/aten::linear/MatMul_4318\n",
      "__module.model.gpt_neox.layers.19.attention/aten::baddbmm/Multiply_4507\n",
      "__module.model.gpt_neox.layers.19.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.19.attention.dense/aten::linear/MatMul_4526\n",
      "__module.model.gpt_neox.layers.20.mlp.dense_h_to_4h/aten::linear/MatMul_4749\n",
      "__module.model.gpt_neox.layers.20.mlp.dense_4h_to_h/aten::linear/MatMul_4758\n",
      "__module.model.gpt_neox.layers.20.attention.query_key_value/aten::linear/MatMul_4540\n",
      "__module.model.gpt_neox.layers.20.attention/aten::baddbmm/Multiply_4729\n",
      "__module.model.gpt_neox.layers.20.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.20.attention.dense/aten::linear/MatMul_4748\n",
      "__module.model.gpt_neox.layers.21.mlp.dense_h_to_4h/aten::linear/MatMul_4971\n",
      "__module.model.gpt_neox.layers.21.mlp.dense_4h_to_h/aten::linear/MatMul_4980\n",
      "__module.model.gpt_neox.layers.21.attention.query_key_value/aten::linear/MatMul_4762\n",
      "__module.model.gpt_neox.layers.21.attention/aten::baddbmm/Multiply_4951\n",
      "__module.model.gpt_neox.layers.21.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.21.attention.dense/aten::linear/MatMul_4970\n",
      "__module.model.gpt_neox.layers.22.mlp.dense_h_to_4h/aten::linear/MatMul_5193\n",
      "__module.model.gpt_neox.layers.22.mlp.dense_4h_to_h/aten::linear/MatMul_5202\n",
      "__module.model.gpt_neox.layers.22.attention.query_key_value/aten::linear/MatMul_4984\n",
      "__module.model.gpt_neox.layers.22.attention/aten::baddbmm/Multiply_5173\n",
      "__module.model.gpt_neox.layers.22.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.22.attention.dense/aten::linear/MatMul_5192\n",
      "__module.model.gpt_neox.layers.23.mlp.dense_h_to_4h/aten::linear/MatMul_5415\n",
      "__module.model.gpt_neox.layers.23.mlp.dense_4h_to_h/aten::linear/MatMul_5424\n",
      "__module.model.gpt_neox.layers.23.attention.query_key_value/aten::linear/MatMul_5206\n",
      "__module.model.gpt_neox.layers.23.attention/aten::baddbmm/Multiply_5395\n",
      "__module.model.gpt_neox.layers.23.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.23.attention.dense/aten::linear/MatMul_5414\n",
      "__module.model.gpt_neox.layers.24.mlp.dense_h_to_4h/aten::linear/MatMul_5637\n",
      "__module.model.gpt_neox.layers.24.mlp.dense_4h_to_h/aten::linear/MatMul_5646\n",
      "__module.model.gpt_neox.layers.24.attention.query_key_value/aten::linear/MatMul_5428\n",
      "__module.model.gpt_neox.layers.24.attention/aten::baddbmm/Multiply_5617\n",
      "__module.model.gpt_neox.layers.24.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.24.attention.dense/aten::linear/MatMul_5636\n",
      "__module.model.gpt_neox.layers.25.mlp.dense_h_to_4h/aten::linear/MatMul_5859\n",
      "__module.model.gpt_neox.layers.25.mlp.dense_4h_to_h/aten::linear/MatMul_5868\n",
      "__module.model.gpt_neox.layers.25.attention.query_key_value/aten::linear/MatMul_5650\n",
      "__module.model.gpt_neox.layers.25.attention/aten::baddbmm/Multiply_5839\n",
      "__module.model.gpt_neox.layers.25.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.25.attention.dense/aten::linear/MatMul_5858\n",
      "__module.model.gpt_neox.layers.26.mlp.dense_h_to_4h/aten::linear/MatMul_6081\n",
      "__module.model.gpt_neox.layers.26.mlp.dense_4h_to_h/aten::linear/MatMul_6090\n",
      "__module.model.gpt_neox.layers.26.attention.query_key_value/aten::linear/MatMul_5872\n",
      "__module.model.gpt_neox.layers.26.attention/aten::baddbmm/Multiply_6061\n",
      "__module.model.gpt_neox.layers.26.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.26.attention.dense/aten::linear/MatMul_6080\n",
      "__module.model.gpt_neox.layers.27.mlp.dense_h_to_4h/aten::linear/MatMul_6303\n",
      "__module.model.gpt_neox.layers.27.mlp.dense_4h_to_h/aten::linear/MatMul_6312\n",
      "__module.model.gpt_neox.layers.27.attention.query_key_value/aten::linear/MatMul_6094\n",
      "__module.model.gpt_neox.layers.27.attention/aten::baddbmm/Multiply_6283\n",
      "__module.model.gpt_neox.layers.27.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.27.attention.dense/aten::linear/MatMul_6302\n",
      "__module.model.gpt_neox.layers.28.mlp.dense_h_to_4h/aten::linear/MatMul_6525\n",
      "__module.model.gpt_neox.layers.28.mlp.dense_4h_to_h/aten::linear/MatMul_6534\n",
      "__module.model.gpt_neox.layers.28.attention.query_key_value/aten::linear/MatMul_6316\n",
      "__module.model.gpt_neox.layers.28.attention/aten::baddbmm/Multiply_6505\n",
      "__module.model.gpt_neox.layers.28.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.28.attention.dense/aten::linear/MatMul_6524\n",
      "__module.model.gpt_neox.layers.29.mlp.dense_h_to_4h/aten::linear/MatMul_6747\n",
      "__module.model.gpt_neox.layers.29.mlp.dense_4h_to_h/aten::linear/MatMul_6756\n",
      "__module.model.gpt_neox.layers.29.attention.query_key_value/aten::linear/MatMul_6538\n",
      "__module.model.gpt_neox.layers.29.attention/aten::baddbmm/Multiply_6727\n",
      "__module.model.gpt_neox.layers.29.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.29.attention.dense/aten::linear/MatMul_6746\n",
      "__module.model.gpt_neox.layers.30.mlp.dense_h_to_4h/aten::linear/MatMul_6969\n",
      "__module.model.gpt_neox.layers.30.mlp.dense_4h_to_h/aten::linear/MatMul_6978\n",
      "__module.model.gpt_neox.layers.30.attention.query_key_value/aten::linear/MatMul_6760\n",
      "__module.model.gpt_neox.layers.30.attention/aten::baddbmm/Multiply_6949\n",
      "__module.model.gpt_neox.layers.30.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.30.attention.dense/aten::linear/MatMul_6968\n",
      "__module.model.gpt_neox.layers.31.mlp.dense_h_to_4h/aten::linear/MatMul_7191\n",
      "__module.model.gpt_neox.layers.31.mlp.dense_4h_to_h/aten::linear/MatMul_7200\n",
      "__module.model.gpt_neox.layers.31.attention.query_key_value/aten::linear/MatMul_6982\n",
      "__module.model.gpt_neox.layers.31.attention/aten::baddbmm/Multiply_7171\n",
      "__module.model.gpt_neox.layers.31.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.31.attention.dense/aten::linear/MatMul_7190\n",
      "__module.model.gpt_neox.layers.32.mlp.dense_h_to_4h/aten::linear/MatMul_7413\n",
      "__module.model.gpt_neox.layers.32.mlp.dense_4h_to_h/aten::linear/MatMul_7422\n",
      "__module.model.gpt_neox.layers.32.attention.query_key_value/aten::linear/MatMul_7204\n",
      "__module.model.gpt_neox.layers.32.attention/aten::baddbmm/Multiply_7393\n",
      "__module.model.gpt_neox.layers.32.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.32.attention.dense/aten::linear/MatMul_7412\n",
      "__module.model.gpt_neox.layers.33.mlp.dense_h_to_4h/aten::linear/MatMul_7635\n",
      "__module.model.gpt_neox.layers.33.mlp.dense_4h_to_h/aten::linear/MatMul_7644\n",
      "__module.model.gpt_neox.layers.33.attention.query_key_value/aten::linear/MatMul_7426\n",
      "__module.model.gpt_neox.layers.33.attention/aten::baddbmm/Multiply_7615\n",
      "__module.model.gpt_neox.layers.33.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.33.attention.dense/aten::linear/MatMul_7634\n",
      "__module.model.gpt_neox.layers.34.mlp.dense_h_to_4h/aten::linear/MatMul_7857\n",
      "__module.model.gpt_neox.layers.34.mlp.dense_4h_to_h/aten::linear/MatMul_7866\n",
      "__module.model.gpt_neox.layers.34.attention.query_key_value/aten::linear/MatMul_7648\n",
      "__module.model.gpt_neox.layers.34.attention/aten::baddbmm/Multiply_7837\n",
      "__module.model.gpt_neox.layers.34.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.34.attention.dense/aten::linear/MatMul_7856\n",
      "__module.model.gpt_neox.layers.35.mlp.dense_h_to_4h/aten::linear/MatMul_8079\n",
      "__module.model.gpt_neox.layers.35.mlp.dense_4h_to_h/aten::linear/MatMul_8088\n",
      "__module.model.gpt_neox.layers.35.attention.query_key_value/aten::linear/MatMul_7870\n",
      "__module.model.gpt_neox.layers.35.attention/aten::baddbmm/Multiply_8059\n",
      "__module.model.gpt_neox.layers.35.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.35.attention.dense/aten::linear/MatMul_8078\n",
      "__module.model.gpt_neox.layers.36.mlp.dense_h_to_4h/aten::linear/MatMul_8301\n",
      "__module.model.gpt_neox.layers.36.mlp.dense_4h_to_h/aten::linear/MatMul_8310\n",
      "__module.model.gpt_neox.layers.36.attention.query_key_value/aten::linear/MatMul_8092\n",
      "__module.model.gpt_neox.layers.36.attention/aten::baddbmm/Multiply_8281\n",
      "__module.model.gpt_neox.layers.36.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.36.attention.dense/aten::linear/MatMul_8300\n",
      "__module.model.gpt_neox.layers.37.mlp.dense_h_to_4h/aten::linear/MatMul_8523\n",
      "__module.model.gpt_neox.layers.37.mlp.dense_4h_to_h/aten::linear/MatMul_8532\n",
      "__module.model.gpt_neox.layers.37.attention.query_key_value/aten::linear/MatMul_8314\n",
      "__module.model.gpt_neox.layers.37.attention/aten::baddbmm/Multiply_8503\n",
      "__module.model.gpt_neox.layers.37.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.37.attention.dense/aten::linear/MatMul_8522\n",
      "__module.model.gpt_neox.layers.38.mlp.dense_h_to_4h/aten::linear/MatMul_8745\n",
      "__module.model.gpt_neox.layers.38.mlp.dense_4h_to_h/aten::linear/MatMul_8754\n",
      "__module.model.gpt_neox.layers.38.attention.query_key_value/aten::linear/MatMul_8536\n",
      "__module.model.gpt_neox.layers.38.attention/aten::baddbmm/Multiply_8725\n",
      "__module.model.gpt_neox.layers.38.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.38.attention.dense/aten::linear/MatMul_8744\n",
      "__module.model.gpt_neox.layers.39.mlp.dense_h_to_4h/aten::linear/MatMul_8967\n",
      "__module.model.gpt_neox.layers.39.mlp.dense_4h_to_h/aten::linear/MatMul_8976\n",
      "__module.model.gpt_neox.layers.39.attention.query_key_value/aten::linear/MatMul_8758\n",
      "__module.model.gpt_neox.layers.39.attention/aten::baddbmm/Multiply_8947\n",
      "__module.model.gpt_neox.layers.39.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.39.attention.dense/aten::linear/MatMul_8966\n",
      "__module.model.gpt_neox.layers.40.mlp.dense_h_to_4h/aten::linear/MatMul_9189\n",
      "__module.model.gpt_neox.layers.40.mlp.dense_4h_to_h/aten::linear/MatMul_9198\n",
      "__module.model.gpt_neox.layers.40.attention.query_key_value/aten::linear/MatMul_8980\n",
      "__module.model.gpt_neox.layers.40.attention/aten::baddbmm/Multiply_9169\n",
      "__module.model.gpt_neox.layers.40.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.40.attention.dense/aten::linear/MatMul_9188\n",
      "__module.model.gpt_neox.layers.41.mlp.dense_h_to_4h/aten::linear/MatMul_9411\n",
      "__module.model.gpt_neox.layers.41.mlp.dense_4h_to_h/aten::linear/MatMul_9420\n",
      "__module.model.gpt_neox.layers.41.attention.query_key_value/aten::linear/MatMul_9202\n",
      "__module.model.gpt_neox.layers.41.attention/aten::baddbmm/Multiply_9391\n",
      "__module.model.gpt_neox.layers.41.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.41.attention.dense/aten::linear/MatMul_9410\n",
      "__module.model.gpt_neox.layers.42.mlp.dense_h_to_4h/aten::linear/MatMul_9633\n",
      "__module.model.gpt_neox.layers.42.mlp.dense_4h_to_h/aten::linear/MatMul_9642\n",
      "__module.model.gpt_neox.layers.42.attention.query_key_value/aten::linear/MatMul_9424\n",
      "__module.model.gpt_neox.layers.42.attention/aten::baddbmm/Multiply_9613\n",
      "__module.model.gpt_neox.layers.42.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.42.attention.dense/aten::linear/MatMul_9632\n",
      "__module.model.gpt_neox.layers.43.attention.query_key_value/aten::linear/MatMul_9646\n",
      "__module.model.gpt_neox.layers.43.mlp.dense_h_to_4h/aten::linear/MatMul_9855\n",
      "__module.model.gpt_neox.layers.43.mlp.dense_4h_to_h/aten::linear/MatMul_9864\n",
      "__module.model.gpt_neox.layers.43.attention/aten::baddbmm/Multiply_9835\n",
      "__module.model.gpt_neox.layers.43.attention/aten::matmul/MatMul\n",
      "__module.model.gpt_neox.layers.43.attention.dense/aten::linear/MatMul_9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import shutil\n",
    "import partially_upcast_nodes_to_fp32\n",
    "import model_upcast_utils\n",
    "import main\n",
    "importlib.reload(partially_upcast_nodes_to_fp32)\n",
    "importlib.reload(main)\n",
    "\n",
    "SAVE_MODEL = bool(1)\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "    batch_size = -1\n",
    "    example_input = main.get_inputs_for_calibration(ov_model_for_causal_lm, tok, example_prompt)\n",
    "    if MODEL_ID in [\"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "        position_ids = np.cumsum(example_input[\"attention_mask\"], axis=1) - 1\n",
    "        position_ids[example_input[\"attention_mask\"] == 0] = 1\n",
    "        example_input[\"position_ids\"] = position_ids\n",
    "elif MODEL_ID == \"T5\":\n",
    "    batch_size = -1\n",
    "    # from diffusers import DiffusionPipeline\n",
    "    # tokenizer = DiffusionPipeline.from_pretrained(\"DeepFloyd/IF-I-M-v1.0\").tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(models_dir / MODEL_ID / \"tokenizer\")\n",
    "    example_input = tokenizer(example_prompt, max_length=77, padding=\"max_length\", return_tensors=\"np\").input_ids\n",
    "elif MODEL_ID == \"tiny-sd-unet\":\n",
    "    batch_size = -1\n",
    "    example_input = unet_example_input\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")\n",
    "\n",
    "# shape_str = \"\"\n",
    "# for k, v in example_input.items():\n",
    "#     # np.save(f\"example_input/{k}.npy\", v.data)\n",
    "#     shape_str += f\"{k}{list(v.shape)},\".replace(' ', '')\n",
    "# print(shape_str)\n",
    "\n",
    "# upcasted_model = model_upcast_utils.partially_upcast_nodes_to_fp32(model, example_input)\n",
    "upcast_ratio = 1.0\n",
    "upcasted_model = partially_upcast_nodes_to_fp32.partially_upcast_nodes_to_fp32(\n",
    "    model, example_input, batch_size=-1, verbose=True, half_type=half_type, upcast_ratio=upcast_ratio)\n",
    "\n",
    "if SAVE_MODEL:\n",
    "    calibrated_model_dir = Path(f\"{model_dir}_calibrated_{upcast_ratio:.2f}\")\n",
    "    if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "        # shutil.copytree(model_dir, calibrated_model_dir)\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"openvino_model.xml\")\n",
    "        for filename in [\"config.json\", \"added_tokens.json\", \"special_tokens_map.json\", \"tokenizer.json\", \"tokenizer_config.json\", \"vocab.json\"]:\n",
    "            if (model_dir / filename).exists():\n",
    "                shutil.copy(str(model_dir / filename), str(calibrated_model_dir / filename))\n",
    "    elif MODEL_ID == \"T5\":\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"encoder_ir.xml\", compress_to_fp16=True)\n",
    "    elif MODEL_ID == \"tiny-sd-unet\":\n",
    "        ov.save_model(upcasted_model, calibrated_model_dir / \"unet.xml\")\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "    ov_model_for_causal_lm.model = upcasted_model\n",
    "    ov_model_for_causal_lm.request = None\n",
    "    ov_model_for_causal_lm.compile()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:32:48.557710100Z",
     "start_time": "2023-12-12T14:24:59.692939900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/home/devuser/nsavelye/venvs/fp16_calibration/lib/python3.8/site-packages/optimum/intel/openvino/modeling_decoder.py:391: FutureWarning: `shared_memory` is deprecated and will be removed in 2024.0. Value of `shared_memory` is going to override `share_inputs` value. Please use only `share_inputs` explicitly.\n",
      "  self.request.start_async(inputs, shared_memory=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which lakes are near Munich?\n",
      "\n",
      "A:\n",
      "\n",
      "The closest lake to Munich is the Ammersee, which is about a 30 minute drive from the city.\n",
      "\n",
      "A:\n",
      "\n",
      "The closest lake to Munich is the Ammersee, which is about a 30 minute drive from the city.\n",
      "\n",
      "A:\n",
      "\n",
      "The closest lake to Munich is the Ammersee, which is about a 30 minute drive from the city.\n",
      "\n",
      "This is not true. The closest lake to Munich is the Ammer"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import main\n",
    "importlib.reload(main)\n",
    "\n",
    "if MODEL_ID in [\"red-pajama-3b-chat\", \"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "    if MODEL_ID in [\"red-pajama-3b-chat\", \"gpt-neox-20b\"]:\n",
    "        prompt = \"Which lakes are near Munich?\"\n",
    "    elif MODEL_ID == \"codegen-2B-multi\":\n",
    "        prompt = example_prompt\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "    if MODEL_ID == \"red-pajama-3b-chat\":\n",
    "        generation_kwargs = dict(\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.1,\n",
    "            do_sample=0.1 > 0.0,\n",
    "            top_p=1.0,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.2\n",
    "        )\n",
    "    elif MODEL_ID in [\"codegen-2B-multi\", \"gpt-neox-20b\"]:\n",
    "        generation_kwargs = dict(\n",
    "            max_new_tokens=100,\n",
    "            num_beams=1,\n",
    "            use_cache=True,\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Unknown model\")\n",
    "\n",
    "    # print(run_generate(ov_model, prompt, model_configuration, **generation_kwargs))\n",
    "    for text in main.run_generate(ov_model_for_causal_lm, tok, prompt, **generation_kwargs):\n",
    "        print(text, end=\"\")\n",
    "elif MODEL_ID == \"T5\":\n",
    "    from IPython.display import display\n",
    "    from deepfloyd_utils import TextEncoder, UnetFirstStage, pt_to_pil\n",
    "    from diffusers import DiffusionPipeline\n",
    "    import torch\n",
    "    import sys\n",
    "\n",
    "    sys.path.append(\"../notebooks/utils\")\n",
    "\n",
    "    prompt = 'ultra close color photo portrait of rainbow owl with deer horns in the woods'\n",
    "    negative_prompt = 'blurred unreal uncentered occluded'\n",
    "\n",
    "    RANDOM_SEED = 42\n",
    "    N_DIFFUSION_STEPS = 50\n",
    "    checkpoint_variant = 'fp16'\n",
    "    model_dtype = torch.float32\n",
    "\n",
    "    stage_1 = DiffusionPipeline.from_pretrained(\n",
    "        \"DeepFloyd/IF-I-M-v1.0\",\n",
    "        variant=checkpoint_variant,\n",
    "        torch_dtype=model_dtype\n",
    "    )\n",
    "\n",
    "    # Initialize TextEncoder wrapper class\n",
    "    stage_1.text_encoder = TextEncoder(calibrated_model_dir / \"encoder_ir_calibrated.xml\", dtype=model_dtype, device=device)\n",
    "\n",
    "    # Generate text embeddings\n",
    "    prompt_embeds, negative_embeds = stage_1.encode_prompt(prompt, negative_prompt=negative_prompt)\n",
    "\n",
    "    # Initialize the First Stage UNet wrapper class\n",
    "    stage_1.unet = UnetFirstStage(\n",
    "        \"/home/guest/nsavelye/workspace/fp16_calibration/notebooks/238-deepfloyd-if/models_new/unet_ir_I.xml\",\n",
    "        stage_1.unet.config,\n",
    "        dtype=model_dtype,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Fix PRNG seed\n",
    "    generator = torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    # Inference\n",
    "    image = stage_1(prompt_embeds=prompt_embeds, negative_prompt_embeds=negative_embeds,\n",
    "                    generator=generator, output_type=\"pt\", num_inference_steps=N_DIFFUSION_STEPS).images\n",
    "\n",
    "    # Show the image\n",
    "    display(pt_to_pil(image)[0])\n",
    "else:\n",
    "    raise Exception(\"Unknown model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T09:31:36.267963400Z",
     "start_time": "2023-12-13T09:30:40.941070800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T14:33:21.796563400Z",
     "start_time": "2023-12-12T14:33:21.795563400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
